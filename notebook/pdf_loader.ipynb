{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32033da9",
   "metadata": {},
   "source": [
    "#### RAG Pipeline - Data Ingestion to Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bcfacdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from langchain_community.document_loaders import PyMuPDFLoader , PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb2acbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 PDF files\n",
      "Processing machine_learning.pdf\n",
      "Loaded 1 pages\n",
      "Processing python_intro.pdf\n",
      "Loaded 1 pages\n",
      "Total documents: 2\n"
     ]
    }
   ],
   "source": [
    "# Reading PDF files\n",
    "\n",
    "def process_pdf(pdf_dir):\n",
    "    '''Process PDF files in a directory'''\n",
    "    \n",
    "    all_doc = []\n",
    "    pdf_directory = Path(pdf_dir)\n",
    "    \n",
    "    pdf_files = list(pdf_directory.glob(\"**/*.pdf\"))\n",
    "    print(f\"Found {len(pdf_files)} PDF files\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"Processing {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # Add Source info\n",
    "            for doc in documents:\n",
    "                doc.metadata[\"source_file\"] = pdf_file.name\n",
    "                doc.metadata[\"file_type\"] = 'pdf'\n",
    "                \n",
    "            all_doc.extend(documents)\n",
    "            print(f\"Loaded {len(documents)} pages\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pdf_file.name}: {e}\")\n",
    "    \n",
    "    print(f\"Total documents: {len(all_doc)}\")\n",
    "    return all_doc\n",
    "\n",
    "# Process PDF files\n",
    "all_doc = process_pdf(\"../data/pdf_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c017de96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-30T18:01:39+05:30', 'author': 'HINATA SHOYO', 'moddate': '2025-10-30T18:01:39+05:30', 'source': '..\\\\data\\\\pdf_files\\\\machine_learning.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'machine_learning.pdf', 'file_type': 'pdf'}, page_content='Machine Learning Basics \\n \\nMachine learning is a subset of artificial intelligence that enables systems to learn and \\nimprove \\nfrom experience without being explicitly programmed. It focuses on developing computer \\nprograms \\nthat can access data and use it to learn for themselves. \\n \\nTypes of Machine Learning: \\n1. Supervised Learning: Learning with labeled data \\n2. Unsupervised Learning: Finding patterns in unlabeled data \\n3. Reinforcement Learning: Learning through rewards and penalties \\n \\nApplications include image recognition, speech processing, and recommendation systems'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-30T18:02:12+05:30', 'author': 'HINATA SHOYO', 'moddate': '2025-10-30T18:02:12+05:30', 'source': '..\\\\data\\\\pdf_files\\\\python_intro.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'python_intro.pdf', 'file_type': 'pdf'}, page_content='Python Programming Introduction \\n \\nPython is a high-level, interpreted programming language known for its simplicity and \\nreadability. \\nCreated by Guido van Rossum and first released in 1991, Python has become one of the \\nmost popular \\nprogramming languages in the world. \\n \\nKey Features: \\n- Easy to learn and use \\n- Extensive standard library \\n- Cross-platform compatibility \\n- Strong community support \\n \\nPython is widely used in web development, data science, artificial intelligence, and \\nautomation.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17580559",
   "metadata": {},
   "source": [
    "#### Text Splitting - get into CHUNKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "442f78f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(documents , chunk_size=1000 , chunk_overlap=200):\n",
    "    '''Splits doc into chunks for better performance'''\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "    \n",
    "    # Simple example\n",
    "    if split_docs:\n",
    "        print(f\"Content: {split_docs[0].page_content}\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "        \n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5d5ec00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 2 documents into 2 chunks\n",
      "Content: Machine Learning Basics \n",
      " \n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn and \n",
      "improve \n",
      "from experience without being explicitly programmed. It focuses on developing computer \n",
      "programs \n",
      "that can access data and use it to learn for themselves. \n",
      " \n",
      "Types of Machine Learning: \n",
      "1. Supervised Learning: Learning with labeled data \n",
      "2. Unsupervised Learning: Finding patterns in unlabeled data \n",
      "3. Reinforcement Learning: Learning through rewards and penalties \n",
      " \n",
      "Applications include image recognition, speech processing, and recommendation systems\n",
      "Metadata: {'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-10-30T18:01:39+05:30', 'author': 'HINATA SHOYO', 'moddate': '2025-10-30T18:01:39+05:30', 'source': '..\\\\data\\\\pdf_files\\\\machine_learning.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'machine_learning.pdf', 'file_type': 'pdf'}\n"
     ]
    }
   ],
   "source": [
    "chunks = split_documents(all_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187d044a",
   "metadata": {},
   "source": [
    "#### Embedding and Vector Store DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5687af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\1.Progress\\RAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List , Dict , Any , Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a195ac7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\1.Progress\\RAG\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\LENOVO\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model all-MiniLM-L6-v2 loaded successfully\n",
      "Embedding Dimensions: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x23bc48b7380>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    '''Handles document embeddings generation using SentenceTransformers'''\n",
    "    \n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        '''\n",
    "        Intialize it\n",
    "        Args : model_name : HuggingFace model for sentence embedding\n",
    "        '''\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "        \n",
    "    def _load_model(self):\n",
    "        '''Protected function to load the model'''\n",
    "        try:\n",
    "            print(f\"Loading model {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model {self.model_name} loaded successfully\\nEmbedding Dimensions: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        '''\n",
    "        Generate embeddings for a list of texts\n",
    "        Args : texts : List of texts to generate embeddings for\n",
    "        Returns : np.ndarray : Embeddings for the texts\n",
    "        '''\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts\")\n",
    "        embeddings = self.model.encode(texts , show_progress_bar=True)\n",
    "        print(f\"Embeddings generated successfully with shape {embeddings.shape}\")\n",
    "        return embeddings\n",
    "    \n",
    "# Intialize the EmbeddingManager\n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12b94f4",
   "metadata": {},
   "source": [
    "#### Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c4aa6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized at ../data/vector_store\n",
      "Collection name: pdf_documents\n",
      "Existing documents in collection: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x23bc5196e40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    '''Manages doc embedding in a Chroma DB vector store'''\n",
    "    \n",
    "    def __init__(self, collection_name: str = \"pdf_documents\",  persist_directory: str = \"../data/vector_store\"):\n",
    "        '''\n",
    "        Intializes the Chroma DB vector store\n",
    "        Args:\n",
    "            collection_name (str): Name of the collection to be created\n",
    "            persist_directory (str): Directory to persist the collection            \n",
    "        '''\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._intialize_store()\n",
    "    \n",
    "    def _intialize_store(self):\n",
    "        '''Intializes the Chroma DB client and collection'''\n",
    "        \n",
    "        try:\n",
    "            '''Create persist directory if it doesn't exist'''\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            \n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata = {'description' : \"PDF Document embeddings for RAG\"}\n",
    "                )\n",
    "            \n",
    "            print(f\"Vector store initialized at {self.persist_directory}\")\n",
    "            print(f\"Collection name: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "        \n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "        \n",
    "        Args:\n",
    "            documents: List of LangChain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "        \n",
    "        # Prepare data for ChromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "        \n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique ID\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "            \n",
    "            # Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "            \n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "            \n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "        \n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vectorstore=VectorStore()\n",
    "vectorstore    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9702f0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine Learning Basics \\n \\nMachine learning is a subset of artificial intelligence that enables systems to learn and \\nimprove \\nfrom experience without being explicitly programmed. It focuses on developing computer \\nprograms \\nthat can access data and use it to learn for themselves. \\n \\nTypes of Machine Learning: \\n1. Supervised Learning: Learning with labeled data \\n2. Unsupervised Learning: Finding patterns in unlabeled data \\n3. Reinforcement Learning: Learning through rewards and penalties \\n \\nApplications include image recognition, speech processing, and recommendation systems',\n",
       " 'Python Programming Introduction \\n \\nPython is a high-level, interpreted programming language known for its simplicity and \\nreadability. \\nCreated by Guido van Rossum and first released in 1991, Python has become one of the \\nmost popular \\nprogramming languages in the world. \\n \\nKey Features: \\n- Easy to learn and use \\n- Extensive standard library \\n- Cross-platform compatibility \\n- Strong community support \\n \\nPython is widely used in web development, data science, artificial intelligence, and \\nautomation.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting Text to Embeddings\n",
    "\n",
    "texts = [doc.page_content for doc in chunks]\n",
    "texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1e4e495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 2 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated successfully with shape (2, 384)\n",
      "Adding 2 documents to vector store...\n",
      "Successfully added 2 documents to vector store\n",
      "Total documents in collection: 2\n"
     ]
    }
   ],
   "source": [
    "# Generate the Embeddings\n",
    "embeddings = embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "# Store in VectorDB\n",
    "vectorstore.add_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f07c44c",
   "metadata": {},
   "source": [
    "### Retriever Pipleine from VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "553939e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RAGRetriever at 0x23bab114d70>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RAGRetriever:\n",
    "    '''Handles query-based retrieval from vector store'''\n",
    "    \n",
    "    def __init__(self, vector_store: VectorStore , embedding_manager: EmbeddingManager):\n",
    "        '''\n",
    "        Intialize the retriever\n",
    "        Args:\n",
    "            vector_store: VectorStore containing the embeddings\n",
    "            embedding_manager: EmbeddingManager to handle embeddings\n",
    "        '''\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "    \n",
    "    def retrieve(self, query: str, top_k: int = 5, score_threshold: float = 0.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for a query\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            top_k: Number of top results to return\n",
    "            score_threshold: Minimum similarity score threshold\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing retrieved documents and metadata\n",
    "        \"\"\"\n",
    "        print(f\"Retrieving documents for query: '{query}'\")\n",
    "        print(f\"Top K: {top_k}, Score threshold: {score_threshold}\")\n",
    "        \n",
    "        # Generate query embedding\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "        \n",
    "        # Search in vector store\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k\n",
    "            )\n",
    "            \n",
    "            # Process results\n",
    "            retrieved_docs = []\n",
    "            \n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "                \n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                    # Convert distance to similarity score (ChromaDB uses cosine distance)\n",
    "                    similarity_score = 1 - distance\n",
    "                    \n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i + 1\n",
    "                        })\n",
    "                \n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "            \n",
    "            return retrieved_docs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "\n",
    "rag_retriever=RAGRetriever(vectorstore,embedding_manager)\n",
    "rag_retriever    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16fa5fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is the python?'\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated successfully with shape (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_96f4ab67_1',\n",
       "  'content': 'Python Programming Introduction \\n \\nPython is a high-level, interpreted programming language known for its simplicity and \\nreadability. \\nCreated by Guido van Rossum and first released in 1991, Python has become one of the \\nmost popular \\nprogramming languages in the world. \\n \\nKey Features: \\n- Easy to learn and use \\n- Extensive standard library \\n- Cross-platform compatibility \\n- Strong community support \\n \\nPython is widely used in web development, data science, artificial intelligence, and \\nautomation.',\n",
       "  'metadata': {'total_pages': 1,\n",
       "   'page_label': '1',\n",
       "   'creator': 'Microsoft® Word for Microsoft 365',\n",
       "   'producer': 'Microsoft® Word for Microsoft 365',\n",
       "   'file_type': 'pdf',\n",
       "   'source': '..\\\\data\\\\pdf_files\\\\python_intro.pdf',\n",
       "   'creationdate': '2025-10-30T18:02:12+05:30',\n",
       "   'doc_index': 1,\n",
       "   'author': 'HINATA SHOYO',\n",
       "   'content_length': 504,\n",
       "   'moddate': '2025-10-30T18:02:12+05:30',\n",
       "   'page': 0,\n",
       "   'source_file': 'python_intro.pdf'},\n",
       "  'similarity_score': 0.6385138630867004,\n",
       "  'distance': 0.36148613691329956,\n",
       "  'rank': 1}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(query=\"What is the python?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1303e7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'machine learning'\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 33.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated successfully with shape (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_76e7c3a2_0',\n",
       "  'content': 'Machine Learning Basics \\n \\nMachine learning is a subset of artificial intelligence that enables systems to learn and \\nimprove \\nfrom experience without being explicitly programmed. It focuses on developing computer \\nprograms \\nthat can access data and use it to learn for themselves. \\n \\nTypes of Machine Learning: \\n1. Supervised Learning: Learning with labeled data \\n2. Unsupervised Learning: Finding patterns in unlabeled data \\n3. Reinforcement Learning: Learning through rewards and penalties \\n \\nApplications include image recognition, speech processing, and recommendation systems',\n",
       "  'metadata': {'producer': 'Microsoft® Word for Microsoft 365',\n",
       "   'creator': 'Microsoft® Word for Microsoft 365',\n",
       "   'doc_index': 0,\n",
       "   'content_length': 581,\n",
       "   'page': 0,\n",
       "   'file_type': 'pdf',\n",
       "   'source_file': 'machine_learning.pdf',\n",
       "   'moddate': '2025-10-30T18:01:39+05:30',\n",
       "   'total_pages': 1,\n",
       "   'source': '..\\\\data\\\\pdf_files\\\\machine_learning.pdf',\n",
       "   'author': 'HINATA SHOYO',\n",
       "   'creationdate': '2025-10-30T18:01:39+05:30',\n",
       "   'page_label': '1'},\n",
       "  'similarity_score': 0.14411473274230957,\n",
       "  'distance': 0.8558852672576904,\n",
       "  'rank': 1}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(query=\"machine learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512a29ad",
   "metadata": {},
   "source": [
    "#### Integration VectorDB + Context pipeline with LLM Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3767de8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple RAG pipeline with Groq LLM\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Intialize the Groq LLM\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(groq_api_key=groq_api_key , model = \"llama-3.1-8b-instant\" , temperature=0.1 , max_tokens=1024)\n",
    "\n",
    "# RAG function ( retreive context + generate answer )\n",
    "def rag_simple(query , retriever , llm , top_k = 3):\n",
    "    \n",
    "    # Retrieve relevant context\n",
    "    results = retriever.retrieve(query , top_k = top_k)\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results]) if results else \"\"\n",
    "    if not context:\n",
    "        return \"No relevant context found\"\n",
    "    \n",
    "    # Generate answer\n",
    "    prompt=f\"\"\"Use the following context to answer the question concisely.\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question: {query}\n",
    "\n",
    "        Answer:\"\"\"\n",
    "    \n",
    "    response = llm.invoke([prompt.format(context=context,query=query)])\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcf0c89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is python?'\n",
      "Top K: 3, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated successfully with shape (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is a high-level, interpreted programming language known for its simplicity and readability.\n"
     ]
    }
   ],
   "source": [
    "answer = rag_simple(\"What is python?\" , rag_retriever , llm)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4d7a92",
   "metadata": {},
   "source": [
    "#### Enhanced RAG Pipeline Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e8373cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Machine Learning'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 21.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated successfully with shape (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed.\n",
      "Sources: [{'source': 'machine_learning.pdf', 'page': 0, 'score': 0.14411473274230957, 'preview': 'Machine Learning Basics \\n \\nMachine learning is a subset of artificial intelligence that enables systems to learn and \\nimprove \\nfrom experience without being explicitly programmed. It focuses on developing computer \\nprograms \\nthat can access data and use it to learn for themselves. \\n \\nTypes of Machin...'}]\n",
      "Confidence: 0.14411473274230957\n",
      "Context Preview: Machine Learning Basics \n",
      " \n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn and \n",
      "improve \n",
      "from experience without being explicitly programmed. It focuses on developing computer \n",
      "programs \n",
      "that can access data and use it to learn for themselves. \n",
      " \n",
      "Types of Machin\n"
     ]
    }
   ],
   "source": [
    "# --- Enhanced RAG Pipeline Features ---\n",
    "def rag_advanced(query, retriever, llm, top_k=5, min_score=0.2, return_context=False):\n",
    "    \"\"\"\n",
    "    RAG pipeline with extra features:\n",
    "    - Returns answer, sources, confidence score, and optionally full context.\n",
    "    \"\"\"\n",
    "    results = retriever.retrieve(query, top_k=top_k, score_threshold=min_score)\n",
    "    if not results:\n",
    "        return {'answer': 'No relevant context found.', 'sources': [], 'confidence': 0.0, 'context': ''}\n",
    "    \n",
    "    # Prepare context and sources\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "    sources = [{\n",
    "        'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "        'page': doc['metadata'].get('page', 'unknown'),\n",
    "        'score': doc['similarity_score'],\n",
    "        'preview': doc['content'][:300] + '...'\n",
    "    } for doc in results]\n",
    "    confidence = max([doc['similarity_score'] for doc in results])\n",
    "    \n",
    "    # Generate answer\n",
    "    prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\"\"\n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "    \n",
    "    output = {\n",
    "        'answer': response.content,\n",
    "        'sources': sources,\n",
    "        'confidence': confidence\n",
    "    }\n",
    "    if return_context:\n",
    "        output['context'] = context\n",
    "    return output\n",
    "\n",
    "# Example usage:\n",
    "result = rag_advanced(\"Machine Learning\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d57fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
